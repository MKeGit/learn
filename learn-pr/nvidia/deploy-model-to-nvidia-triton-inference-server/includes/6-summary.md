In this module, you learned how to:

- Create an NVIDIA GPU Accelerated Virtual Machine.
- Configure NVIDIA Triton Inference Server and related prerequisites.
- Execute an inference workload on NVIDIA Triton Inference Server.

## Summary

The development team successfully implemented a full custom object detection solution in their line of business. The team used Azure Machine Learning studio to operationalize the gathering and tagging of image samples. They were also able to streamline the ability to train new models using GPU accelerated compute instances. Now they concluded the project by deploying their model to an NVIDIA Triton Inference Server and verified that the model is now ready to go into production at the manufacturing site.

## Learn more

- To ensure you have the best resources to do your lifeâ€™s work, join the [NVIDIA Developer Program](https://developer.nvidia.com/join) and access free Software Development Kits (SDKs), technical documentation, and peer and domain expert help.
- To Advance your knowledge in AI, accelerated computing, accelerated data science, graphics, and simulation. View a full list of self-paced courses and explore instructor-led training opportunities from the [NVIDIA Deep Learning Institute](https://www.nvidia.com/dli).