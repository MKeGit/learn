### YamlMime:ModuleUnit
uid: learn.nvidia.deploy-model-nvidia-triton-inference-server.execute-inference-workload-nvidia-triton-inference-server
title: Execute inference workload on NVIDIA Triton Inference Server
metadata:
  title: Execute inference workload on NVIDIA Triton Inference Server
  description: Execute inference workload on NVIDIA Triton Inference Server.
  author: toolboc
  ms.author: chnoring
  ms.date: 04/11/2022
  ms.custom: team=nextgen
  ms.topic: unit
durationInMinutes: 10
content: |
  [!include[](includes/4-execute-inference-workload-nvidia-triton-inference-server.md)]
