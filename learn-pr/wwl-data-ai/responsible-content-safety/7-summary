# Summary
  
The proliferation of user-generated content has made it near-impossible for human moderators to effectively manage online platforms. Yet as the amount of user-generated content grows, so does the importance of online safety.

Azure AI Content Safety uses AI models to automatically detect violent, sexual, self-harm or hateful language in real time. By allocating a severity level, human moderators can focus on high-priority cases and be exposed to a smaller amount of disturbing content. Azure AI Content Safety includes features to moderate both people-generated and AI-generated material.

In this module, you've seen how the features of Azure AI Content Safety can help e-commerce, brands, gaming companies, and educators to provide safer spaces for users.
