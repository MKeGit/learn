Azure AI model catalog offers the best selection of models:

- Large language models and small language models:
    - Flagship LLMs like GPT-4
    - Small language models
        - Phi3
        - Mistral OSS
        - Llama3 8b
        - Ministral
- Modalities, tasks, and tools:
    - Multi-modal
    - Image generation
    - Embedding models
- Regional and domain specific:
    - Core42 JAIS Arabic language LLM
    - Mistral Large is focused on European languages
    - Nixtla TimeGEN-1 Timeseries forecasting
- Open and proprietary
    - Premium models first on Azure: OpenAI, Mistral Large, Cohere Command R+
    - 1.6K+ open models from Hugging Face
    - Open models from Meta, Databricks, Snowflake and NVIDIA.

Using models through the model catalog meets the key enterprise requirements for usage:

- Data and privacy: you get to decide what happens with your data.
- Security and compliance: built-in security.
- Responsible AI and content safety: evaluations and content safety.

## Paradox of choice - to structured process for selection

Model choice challenge
When the hype around LLMs started we only had a few models to choose from. Now we have hundreds, if not thousands of available models. The main challenge now is to choose a model and not have the risk of investing in integrating a model that may not satisfy your needs.

One part of this is to discover, filter, and deploy the right model.

Two steps:
1. Reduce 1800+ models to a handful of choices.
1. Evaluate the handful to find the best fit for the app.

There are three different catalogs you can look at to explore which model best fits your needs.

## Filter models for characteristics

Before you can browse through the available models to find the best model for your use case, you need to decide on what criteria you're using to filter the models. The criteria are the necessary characteristics you identify for a model. Four characteristics you can consider are:

- **Task type**: What type of task do you need the model to perform? Does it include the understanding of only text, or also audio, or video, or multiple modalities?
- **Precision**: Is the base model good enough or do you need a fine-tuned model that is trained on a specific skill or dataset?
- **Openness**: Do you want to be able to fine-tune the model yourself?
- **Deployment**: Do you want to deploy the model locally, on a serverless endpoint, or do you want to manage the deployment infrastructure?

Let's explore in more detail how precision can be an important filter when choosing a model.


