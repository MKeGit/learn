Azure AI Content Safety detects harmful user-generated and AI-generated content in applications and services. The features within Azure AI Content Safety can help make sure that product reviews, forum posts, and images, align with Contoso Camping Storeâ€™s content guidelines.

Azure AI content safety offers a suite of features designed to monitor and moderate content in real-time. It includes:

- **Text Moderation**: Detects and filters out harmful content in text, such as hate speech, violence, or inappropriate language.

- **Image Moderation**: Analyzes images to identify and block content that might be considered unsafe or offensive.

- **Multimodal Content Analysis**: Works across different types of content, ensuring a comprehensive content safety strategy.

- **Groundedness** **Detection**: Detects and blocks incorrect information in model outputs, ensuring that the text responses of large language models are factual and accurate, based on the source materials provided.

- **Prompt Shields**: Analyzes Large Language Model (LLM) inputs and detects user Prompt attacks and Document attacks.

- **Protected Material Detection**: Identifies and blocks outputs that could potentially violate copyright by scanning for matches against an index of third-party text content, including songs, news articles, recipes, and selected web content.

These features are built on cutting-edge AI models that can detect a wide range of potential risks, threats, and quality issues. Identifying these issues helps you ensure a safe and inclusive environment for all users of the Contoso Camping Store website.