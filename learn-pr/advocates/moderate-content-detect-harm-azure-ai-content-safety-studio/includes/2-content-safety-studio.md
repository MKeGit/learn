Azure AI Content Safety detects harmful user-generated and AI-generated content in applications and services. The features in Azure AI Content Safety can help make sure that product reviews, forum posts, and images align with Contoso Camping Store's content guidelines.

Azure AI Content Safety offers a suite of features for monitoring and moderating content in real time:

- **Text moderation**: Detects and filters out harmful content in text, such as hate speech, violence, or inappropriate language.

- **Image moderation**: Analyzes images to identify and block content that might be considered unsafe or offensive.

- **Multimodal content analysis**: Works across various types of content to help ensure a comprehensive strategy for content safety.

- **Groundedness detection**: Detects and blocks incorrect information in model outputs. It helps ensure that the text responses of large language models are factual and accurate, based on the provided source materials.

- **Prompt shields**: Analyze large language model (LLM) inputs to detect user prompt attacks and document attacks.

- **Protected material detection**: Identifies and blocks outputs that could potentially violate copyrights. It scans for matches against an index of third-party text content, including songs, news articles, recipes, and selected web content.

These features are built on AI models that can detect a wide range of potential risks, threats, and quality problems. Identifying these problems helps you ensure a safe and inclusive environment for all users of the Contoso Camping Store website.
