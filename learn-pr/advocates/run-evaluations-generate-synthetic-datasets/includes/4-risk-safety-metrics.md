Risk & safety metrics are essential as they measure the tendency of AI systems to generate harmful, unsafe, or otherwise undesirable outputs. These metrics help in identifying potential risks and formulating mitigation strategies to address them. The key reasons these metrics matter include:

- **Measuring Harm**: Identifying and quantifying harmful content generated by AI systems to help ensure they do not spread misinformation, hate speech, or other malicious content.
- **Influencing Mitigation Strategy**: Providing actionable insights that can help in developing plans to mitigate identified risks and improve the overall safety of AI applications.
- **Building Trust**: Enhancing user trust by demonstrating a commitment to safety and responsibility in AI deployments.

## Scenario

Contoso Tales is developing an app that generates creative, age-appropriate campfire stories for children, tailored to their reading levels. The app builds on the story plot with input from the reader to craft unique, imaginative stories.

## Instructions

In this exercise, you will assess an AI-generated excerpt for harm using risk and safety metrics. Open the `evaluate-risk-safety.ipynb` file to get started.

## Metrics

Provided is a table of our built-in risk and safety metrics: