In this workshop, you learned how to utilize Azure AI Content Safety APIs. You’re now ready to integrate this resource into Contoso Camping Store’s AI-powered platform!

As you continue in your journey in developing AI responsibly, remember to keep responsible AI principles at the forefront of your approach to integrating AI. Mitigating potential harms presented by generative AI models requires an iterative, layered approach that includes experimentation and measurement. Azure AI integrates years of AI policy, research, and engineering expertise from Microsoft so your teams can build safe, secure, and reliable AI solutions from the start, and leverage enterprise controls for data privacy, compliance, and security on infrastructure that is built for AI at scale.

After completing the project, you might wish to clean up your development environment or return it to its typical state.

###### [Develop in browser](#tab/github-codespaces)

Deleting the GitHub Codespaces environment ensures that you can maximize the amount of free core hours entitlement you get for your account.

1. Sign into the GitHub Codespaces dashboard (<https://github.com/codespaces>).

1. Locate your currently running codespace in the list of codespaces.

1. Open the context menu for the codespace and then select **Delete**.

###### [Develop locally](#tab/visual-studio-code)

You aren't necessarily required to clean up your local environment, but you can stop the running development container and return to running Visual Studio Code in the context of a local workspace.

1. Open the **Command Palette**.

1. Search for and then select **Dev Containers: Reopen Folder Locally**.

> [!TIP]
> Visual Studio Code will stop the running development container, but the container still exists in Docker in a stopped state. You always have the option to deleting the container instance, container image, and volumes from Docker to free up more space on your local machine.

---

### Learn more

- [Infuse responsible AI tools and practices in your LLMops](https://azure.microsoft.com/blog/infuse-responsible-ai-tools-and-practices-in-your-llmops/)
- [Harm categories in Azure AI Content Safety](/azure/ai-services/content-safety/concepts/harm-categories?tabs=warning)
- [Prompt Shields](/azure/ai-services/content-safety/concepts/jailbreak-detection)
- [Groundedness detection](/azure/ai-services/content-safety/concepts/groundedness)