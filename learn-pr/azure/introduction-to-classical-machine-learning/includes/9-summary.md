Well done for getting through all of that! Let's recap what we covered:

- Supervised learning is a kind of learning by example. A model makes predictions, the predictions are compared to expected labels, and the model is then updated to produce better results.
- A cost function is a mathematical way to describe what we want a model to learn. Cost functions calculate large numbers when a model isn't making good predictions, and small numbers when it's performing well.
- Gradient descent is an optimization algorithm. It's way of calculating how to improve a model, when given a cost function and some data.
- Step size (learning rate) changes how quickly and how well the gradient descent algorithm performs.
