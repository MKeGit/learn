
In today's data-driven world, there's great demand for machine learning models that not only excel in accuracy but also adhere to ethical principles. The Responsible AI dashboard provides data scientists and AI developers with the essential tools necessary to craft machine learning models that prioritize societal well-being and inspire trust. This dashboard empowers us to confront crucial concerns like discrimination, inclusiveness, transparency, and fairness in machine learning. Traditional machine learning model evaluation metrics frequently fall short in identifying responsible AI issues. They can also lack when encompassing fairness, inclusiveness, reliability/safety, privacy and security, accountability, and transparency. Practical tools like the Responsible AI dashboard are instrumental in comprehending the societal impact of your AI model and, most importantly, how to improve it to be less harmful.

In the lab later in this module, we use the University of California, Irvine (UCI) hospital diabetes dataset to train a classification model using the Scikit-Learn framework. The model predicts whether or not a patient who has diabetes is likely to be readmitted back to a hospital within 30 days of being discharged.

> [!NOTE]
> The lab environment needed to complete the lab exercise in this unit is temporarily unavailable.

## Learning objectives

In this module, you learn how to:

- Create a responsible AI dashboard.
- Identify where the model has errors.
- Mitigate biases by discovering data that is over or under represented.
- Understand what drives a model outcome with explainable and interpretability.
- Mitigate issues to meet compliance regulation requirements.
