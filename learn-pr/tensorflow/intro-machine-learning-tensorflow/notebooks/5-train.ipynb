{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
        "\n",
        "import gzip\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from typing import Tuple"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You've already seen how to train a neural network using Keras in module 1. In this notebook, you reimplement the training loop in TensorFlow. This helps you understand what goes on under the hood a bit better, gives you the opportunity to customize the training loop if you want, and allows you to debug it.\n",
        "\n",
        "Start by including code that gives us the datasets and model that you use in the remainder of this notebook. You use the same FashionMNIST dataset and data loading code as in module 1, so feel free to re-visit that module if something isn't clear, or take a look [at the source code](https://github.com/MicrosoftDocs/tensorflow-learning-path/blob/main/intro-tf/tintro.py)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget -Nq https://raw.githubusercontent.com/MicrosoftDocs/tensorflow-learning-path/main/intro-tf/tintro.py\n",
        "from tintro import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we mentioned in module 1, the goal of training the neural network is to find parameters $W$ and $b$ that minimize the loss function, which measures the difference between the actual and predicted labels. We also mentioned that you can think of the neural network as the function $\\ell$ below, and that you use an optimization algorithm to find the parameters $W$ and $b$ that minimize this function.\n",
        "\n",
        "$$\n",
        "\\mathrm{loss} = \\ell(X, y, W, b)\n",
        "$$\n",
        "\n",
        "Let's now dig deeper into what this optimization algorithm might look like. There are many types of optimization algorithms, but this tutorial covers only the simplest one: the gradient descent algorithm. To implement gradient descent, you iteratively improve your estimates of $W$ and $b$ according to the update formulas below, until the gradients are smaller than a pre-defined threshold $\\epsilon$ (or for a pre-defined number of times):\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "  W &:= W - \\alpha \\frac{\\partial \\ell}{\\partial W} \\\\\n",
        "  b &:= b - \\alpha \\frac{\\partial \\ell}{\\partial b}\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "The parameter $\\alpha$ is typically referred to as the *learning rate*, and is defined later in the code. \n",
        "\n",
        "When doing training, pass a mini-batch of data as input, perform a sequence of calculations to obtain the loss, then propagate back through the network to calculate the derivatives used in the gradient descent formulas above. Once you have the derivatives, you can update the values of the network's parameters $W$ and $b$ according to the formulas. This sequence of steps is the *backpropagation* algorithm. By performing these calculations several times, your parameters get updated repeatedly, getting more and more accurate each time. \n",
        "\n",
        "In Keras, when you called the function [fit](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit), the backpropagation algorithm was executed several times. Here, start by understanding the code that reflects a single pass of the backpropagation algorithm:\n",
        "\n",
        "- A forward pass through the model to compute the predicted value, `y_prime = model(X, training=True)`\n",
        "- A calculation of the loss using a loss function, `loss = loss_fn(y, y_prime)`\n",
        "- A backward pass from the loss function through the model to calculate derivatives, `grads = tape.gradient(loss, model.trainable_variables)`\n",
        "- A gradient descent step to update $W$ and $b$ using the derivatives calculated in the backward pass, `optimizer.apply_gradients(zip(grads, model.trainable_variables))`\n",
        "\n",
        "Here's the complete code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fit_one_batch(X, y, model, loss_fn, optimizer) -> Tuple[tf.Tensor, tf.Tensor]:\n",
        "  with tf.GradientTape() as tape:\n",
        "    y_prime = model(X, training=True)\n",
        "    loss = loss_fn(y, y_prime)\n",
        "\n",
        "  grads = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "  return (y_prime, loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notice that the code above ensures that the forward calculations are within the `GradientTape`'s scope, just as you saw in the previous notebook. This makes it possible to ask the tape for the gradients. \n",
        "\n",
        "The code above works for a single mini-batch, which is typically much smaller than the full set of data (this sample uses a mini-batch of size 64, out of 60,000 training data items). But you want to execute the backpropagation algorithm for the full set of data. You can do so by iterating through the `Dataset` that you created earlier, which, as you saw in module 1, returns a mini-batch per iteration. There are two critical lines in the code below: the `for` loop and the call to the `fit_one_batch` function. The rest of the code just prints the accuracy and loss as the model is being trained. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fit(dataset: tf.data.Dataset, model: tf.keras.Model, loss_fn: tf.keras.losses.Loss, \n",
        "optimizer: tf.optimizers.Optimizer) -> None:\n",
        "  loss_sum = 0\n",
        "  correct_item_count = 0\n",
        "  current_item_count = 0\n",
        "  print_every = 100\n",
        "  batch_loss = 0\n",
        "  batch_index = 0\n",
        "\n",
        "  for (X, y) in dataset:\n",
        "    (y_prime, loss) = fit_one_batch(X, y, model, loss_fn, optimizer)\n",
        "\n",
        "    y = tf.cast(y, tf.int64)\n",
        "    correct_item_count += (tf.math.argmax(y_prime, axis=1) == y).numpy().sum()\n",
        "\n",
        "    batch_loss = loss.numpy()\n",
        "    loss_sum += batch_loss\n",
        "    current_item_count += len(X)\n",
        "    batch_index += 1\n",
        "\n",
        "    if ((batch_index) % print_every == 0):\n",
        "      batch_accuracy = correct_item_count / current_item_count * print_every\n",
        "      print(f'[Batch {batch_index:>3d} - {current_item_count:>5d} items] accuracy: {batch_accuracy:>0.1f}%, loss: {batch_loss:>7f}')\n",
        "\n",
        "  batch_accuracy = correct_item_count / current_item_count * print_every\n",
        "  print(f'[Batch {batch_index:>3d} - {current_item_count:>5d} items] accuracy: {batch_accuracy:>0.1f}%, loss: {batch_loss:>7f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A complete iteration over all mini-batches in the dataset is called an *epoch*. In this sample, you restrict the code to just five epochs for quick execution, but in a real project you would want to set it to a much higher number to achieve better predictions. The code below also shows the creation of the loss function and optimizer, which was discussed in module 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "learning_rate = 0.1\n",
        "batch_size = 64\n",
        "epochs = 5\n",
        "\n",
        "(train_dataset, test_dataset) = get_data(batch_size)\n",
        "\n",
        "model = NeuralNetwork()\n",
        "\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "optimizer = tf.optimizers.SGD(learning_rate)\n",
        "\n",
        "print('\\nFitting:')\n",
        "for epoch in range(epochs):\n",
        "  print(f'\\nEpoch {epoch + 1}\\n-------------------------------')\n",
        "  fit(train_dataset, model, loss_fn, optimizer)"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "a7d8d32a02de2fe32a77a4e581138922e011c09664b6c2991156e76c4176efab"
    },
    "kernel_info": {
      "name": "azureml_py38_PT_and_TF"
    },
    "kernelspec": {
      "display_name": "azureml_py38",
      "language": "python",
      "name": "conda-env-azureml_py38-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
