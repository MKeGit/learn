{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Up until now, you've been running your code in *eager execution* mode, which is enabled by default. In this mode, the flow of code execution happens in the order you're accustomed to, and you can add breakpoints and inspect the values of our tensors and variables as usual.\n",
        "\n",
        "In contrast, when in [graph execution](https://www.tensorflow.org/guide/intro_to_graphs) mode, the code execution flows a bit differently. During the first pass through the code, a computation graph is created containing information about the operations and tensors in that code. Then in subsequent passes, the graph is used instead of the Python code. One consequence of this flow is that our code isn't debuggable in the usual manner. You gain two major advantages though:\n",
        "- The graph can be deployed to environments that don't have Python, such as embedded devices. \n",
        "- The graph can take advantage of several performance optimizations, such as running parts of the code in parallel.\n",
        "\n",
        "In order to get the best of both worlds, you use eager execution mode during the development phase, and then switch to graph execution mode once you're done debugging the model. To switch from eager to graph execution, you can add the `@tf.function` decorator to the function containing your model operations.\n",
        "\n",
        "Let's look at the training code again, but this time with the `@tf.function` decorator applied to the `fit_one_batch` function, which is where you have all the model operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget -Nq https://raw.githubusercontent.com/MicrosoftDocs/tensorflow-learning-path/main/intro-tf/tintro.py\n",
        "from tintro import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def fit_one_batch(X: tf.Tensor, y: tf.Tensor, model: tf.keras.Model, loss_fn: tf.keras.losses.Loss, \n",
        "optimizer: tf.keras.optimizers.Optimizer) -> Tuple[tf.Tensor, tf.Tensor]:\n",
        "  with tf.GradientTape() as tape:\n",
        "    y_prime = model(X, training=True)\n",
        "    loss = loss_fn(y, y_prime)\n",
        "\n",
        "  grads = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "  return (y_prime, loss)\n",
        "\n",
        "\n",
        "def fit(dataset: tf.data.Dataset, model: tf.keras.Model, loss_fn: tf.keras.losses.Loss, \n",
        "optimizer: tf.optimizers.Optimizer) -> None:\n",
        "  loss_sum = 0\n",
        "  correct_item_count = 0\n",
        "  current_item_count = 0\n",
        "  print_every = 100\n",
        "  batch_loss = 0\n",
        "  batch_index = 0\n",
        "\n",
        "  for (X, y) in dataset:\n",
        "    (y_prime, loss) = fit_one_batch(X, y, model, loss_fn, optimizer)\n",
        "\n",
        "    y = tf.cast(y, tf.int64)\n",
        "    correct_item_count += (tf.math.argmax(y_prime, axis=1) == y).numpy().sum()\n",
        "\n",
        "    batch_loss = loss.numpy()\n",
        "    loss_sum += batch_loss\n",
        "    current_item_count += len(X)\n",
        "    batch_index += 1\n",
        "\n",
        "    if ((batch_index) % print_every == 0):\n",
        "      batch_accuracy = correct_item_count / current_item_count * print_every\n",
        "      print(f'[Batch {batch_index:>3d} - {current_item_count:>5d} items] accuracy: {batch_accuracy:>0.1f}%, loss: {batch_loss:>7f}')\n",
        "\n",
        "  batch_accuracy = correct_item_count / current_item_count * print_every\n",
        "  print(f'[Batch {batch_index:>3d} - {current_item_count:>5d} items] accuracy: {batch_accuracy:>0.1f}%, loss: {batch_loss:>7f}')\n",
        "\n",
        "\n",
        "learning_rate = 0.1\n",
        "batch_size = 64\n",
        "epochs = 5\n",
        "\n",
        "(train_dataset, test_dataset) = get_data(batch_size)\n",
        "\n",
        "model = NeuralNetwork()\n",
        "\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "optimizer = tf.optimizers.SGD(learning_rate)\n",
        "\n",
        "print('\\nFitting:')\n",
        "t_begin = time.time()\n",
        "for epoch in range(epochs):\n",
        "  print(f'\\nEpoch {epoch + 1}\\n-------------------------------')\n",
        "  fit(train_dataset, model, loss_fn, optimizer)\n",
        "t_elapsed = time.time() - t_begin\n",
        "print(f'\\nTime per epoch: {t_elapsed / epochs :>.3f} sec' )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notice that you also add a timer, and print the time it takes to train. You can comment and uncomment the `@tf.function` decorator, and notice the difference between the elapsed times. Eager execution can take more than twice the amount of time to train, compared to graph execution.\n",
        "\n",
        "Now that you've trained your model, you're ready to test it, which you can do by running a single pass forward through the network. The function `evaluate_one_batch` contains the code that does this: you simply need to call the `model` to get a prediction, followed by the loss function `loss_fn` to get a score for how the predicted labels `y_prime` compare to the actual labels `y`. Notice that you don't add a `tf.GradientTape()` this time. That's because, since you don't do a backward pass during testing, you don't need to calculate derivatives for gradient descent. Notice also that we add a `@tf.function` decorator once you're done with development and debugging, to get a performance boost.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def evaluate_one_batch(X: tf.Tensor, y: tf.Tensor, model: tf.keras.Model, \n",
        "loss_fn: tf.keras.losses.Loss) -> Tuple[tf.Tensor, tf.Tensor]:\n",
        "  y_prime = model(X, training=False)\n",
        "  loss = loss_fn(y, y_prime)\n",
        "\n",
        "  return (y_prime, loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `evaluate` function calls the `evaluate_one_batch` function for the entire dataset, once per mini-batch. The important code in the function below is just the `for` loop and the call to `evaluate_one_batch` within it. The rest is just boilerplate code to print progress during execution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate(dataset: tf.data.Dataset, model: tf.keras.Model, \n",
        "loss_fn: tf.keras.losses.Loss) -> Tuple[float, float]:\n",
        "  batch_count = 0\n",
        "  loss_sum = 0\n",
        "  correct_item_count = 0\n",
        "  current_item_count = 0\n",
        "\n",
        "  for (X, y) in dataset:\n",
        "    (y_prime, loss) = evaluate_one_batch(X, y, model, loss_fn)\n",
        "\n",
        "    correct_item_count += (tf.math.argmax(y_prime, axis=1).numpy() == y.numpy()).sum()\n",
        "    loss_sum += loss.numpy()\n",
        "    current_item_count += len(X)\n",
        "    batch_count += 1\n",
        "\n",
        "  average_loss = loss_sum / batch_count\n",
        "  accuracy = correct_item_count / current_item_count\n",
        "  return (average_loss, accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And finally, you print the test loss and accuracy, and save the learned model parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('\\nEvaluating:')\n",
        "(test_loss, test_accuracy) = evaluate(test_dataset, model, loss_fn)\n",
        "print(f'Test accuracy: {test_accuracy * 100:>0.1f}%, test loss: {test_loss:>8f}')\n",
        "\n",
        "model.save_weights('outputs/weights')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The training loss and accuracy should be similar to the values you obtained with the Keras code. "
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "a7d8d32a02de2fe32a77a4e581138922e011c09664b6c2991156e76c4176efab"
    },
    "kernel_info": {
      "name": "azureml_py38_PT_and_TF"
    },
    "kernelspec": {
      "display_name": "azureml_py38",
      "language": "python",
      "name": "conda-env-azureml_py38-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
